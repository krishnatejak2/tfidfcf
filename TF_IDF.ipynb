{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source :\n",
    "https://github.com/williamscott701/Information-Retrieval/blob/master/2.%20TF-IDF%20Ranking%20-%20Cosine%20Similarity%2C%20Matching%20Score/TF-IDF.ipynb\n",
    "\n",
    "https://github.com/mayank408/TFIDF/blob/master/TFIDF.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from num2words import num2words\n",
    "from sklearn.model_selection import *\n",
    "\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Random Data with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "data = open('data/corpus').read()\n",
    "labels, texts = [], []\n",
    "for i, line in enumerate(data.split(\"\\n\")):\n",
    "    content = line.split()\n",
    "    labels.append(content[0])\n",
    "    texts.append(\" \".join(content[1:]))\n",
    "\n",
    "# create a dataframe using texts and lables\n",
    "trainDF = pd.DataFrame()\n",
    "trainDF['text'] = texts\n",
    "trainDF['label'] = labels\n",
    "\n",
    "# split the dataset into training and validation datasets \n",
    "train_x, valid_x, train_y, valid_y = train_test_split(trainDF, trainDF['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0     Stuning even for the non-gamer: This sound tra...\n1     The best soundtrack ever to anything.: I'm rea...\n2     Amazing!: This soundtrack is my favorite music...\n3     Excellent Soundtrack: I truly like this soundt...\n4     Remember, Pull Your Jaw Off The Floor After He...\n                            ...                        \n94    Thank you for Releasing it!!!!!: I loved this ...\n95    Very Not Worth Your Time: The book was wriiten...\n96    Very fun and educational: Trains, shapes and p...\n97    Ludicrous and silly: I remember getting this b...\n98    Artistry: I think that the Deodato concerts ar...\nName: text, Length: 99, dtype: object"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "trainDF['text'][0:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                   text       label\n0     a great cooooooooooooool album.: don't blive t...  __label__2\n1     The autobiography of \"EVERY\" Caribbean mother....  __label__2\n2     Really usable: With 120 knots/bends/etc, this ...  __label__2\n3     Spine Chilling, Awesome, and Grand!: I can not...  __label__2\n4     Buy something else: The dvd is a documentory, ...  __label__1\n...                                                 ...         ...\n7495  heat therapy: I used this product a couple of ...  __label__1\n7496  Not her best...........: Before I begin, let m...  __label__1\n7497  Great movie!: Great movie from my childhood! L...  __label__2\n7498  This book changed the way I look at all books....  __label__2\n7499  sandler is da bomb: 8 crazy nights was a movie...  __label__2\n\n[7500 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a great cooooooooooooool album.: don't blive t...</td>\n      <td>__label__2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The autobiography of \"EVERY\" Caribbean mother....</td>\n      <td>__label__2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Really usable: With 120 knots/bends/etc, this ...</td>\n      <td>__label__2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Spine Chilling, Awesome, and Grand!: I can not...</td>\n      <td>__label__2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Buy something else: The dvd is a documentory, ...</td>\n      <td>__label__1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7495</th>\n      <td>heat therapy: I used this product a couple of ...</td>\n      <td>__label__1</td>\n    </tr>\n    <tr>\n      <th>7496</th>\n      <td>Not her best...........: Before I begin, let m...</td>\n      <td>__label__1</td>\n    </tr>\n    <tr>\n      <th>7497</th>\n      <td>Great movie!: Great movie from my childhood! L...</td>\n      <td>__label__2</td>\n    </tr>\n    <tr>\n      <th>7498</th>\n      <td>This book changed the way I look at all books....</td>\n      <td>__label__2</td>\n    </tr>\n    <tr>\n      <th>7499</th>\n      <td>sandler is da bomb: 8 crazy nights was a movie...</td>\n      <td>__label__2</td>\n    </tr>\n  </tbody>\n</table>\n<p>7500 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train_x.reset_index(inplace = True)\n",
    "valid_x.reset_index(inplace = True)\n",
    "\n",
    "train_x.drop(columns = ['index'],inplace= True)\n",
    "valid_x.drop(columns = ['index'],inplace= True)\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## small data for testing\n",
    "# docA = \"The cat sat on my face\"\n",
    "# docB = \"The dog sat on my bed\"\n",
    "# docC = \"The cat sat on my face\"\n",
    "# docD = \"The dog sat on my bed\"\n",
    "# data = pd.DataFrame()\n",
    "# data['text'] = [docA,docB,docC,docD]\n",
    "# data['label'] = ['a','b','a','b']\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class to generate TF-IDF-CF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_tftdfcf():\n",
    "    import math\n",
    "    def __init__(self,original_data):\n",
    "        self.wordSet = {}\n",
    "        for doc_2 in original_data.text:\n",
    "            doc_2 = doc_2.split(\" \")\n",
    "            self.wordSet = set(self.wordSet).union(set(doc_2))\n",
    "\n",
    "\n",
    "    def convert_lower_case(self,data):\n",
    "        return np.char.lower(data)\n",
    "\n",
    "    def remove_stop_words(self,data):\n",
    "        stop_words = stopwords.words('english')\n",
    "        words = word_tokenize(str(data))\n",
    "        new_text = \"\"\n",
    "        for w in words:\n",
    "            if w not in stop_words and len(w) > 1:\n",
    "                new_text = new_text + \" \" + w\n",
    "        return new_text\n",
    "    def remove_punctuation(self,data):\n",
    "        symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "        for i in range(len(symbols)):\n",
    "            data = np.char.replace(data, symbols[i], ' ')\n",
    "            data = np.char.replace(data, \"  \", \" \")\n",
    "        data = np.char.replace(data, ',', '')\n",
    "        return data\n",
    "    def remove_apostrophe(self,data):\n",
    "        return np.char.replace(data, \"'\", \"\")\n",
    "    def stemming(self,data):\n",
    "        stemmer= PorterStemmer()\n",
    "        \n",
    "        tokens = word_tokenize(str(data))\n",
    "        new_text = \"\"\n",
    "        for w in tokens:\n",
    "            new_text = new_text + \" \" + stemmer.stem(w)\n",
    "        return new_text\n",
    "    def convert_numbers(self,data):\n",
    "        tokens = word_tokenize(str(data))\n",
    "        new_text = \"\"\n",
    "        for w in tokens:\n",
    "            try:\n",
    "                w = num2words(int(w))\n",
    "            except:\n",
    "                a = 0\n",
    "            new_text = new_text + \" \" + w\n",
    "        new_text = np.char.replace(new_text, \"-\", \" \")\n",
    "        return new_text\n",
    "\n",
    "    def preprocess(self,data):\n",
    "        data = self.convert_lower_case(data)\n",
    "        data = self.remove_punctuation(data) #remove comma seperately\n",
    "        data = self.remove_apostrophe(data)\n",
    "        data = self.remove_stop_words(data)\n",
    "        data = self.convert_numbers(data)\n",
    "        data = self.stemming(data)\n",
    "        data = self.remove_punctuation(data)\n",
    "        data = self.convert_numbers(data)\n",
    "        data = self.stemming(data) #needed again as we need to stem the words\n",
    "        data = self.remove_punctuation(data) #needed again as num2word is giving few hypens and commas fourty-one\n",
    "        data = self.remove_stop_words(data) #needed again as num2word is giving stop words 101 - one hundred and one\n",
    "        return data\n",
    "\n",
    "    def get_valid_data(self,data_frame):\n",
    "        self.data_frame = data_frame\n",
    "        self.word_count = []\n",
    "        self.word_count_label = []\n",
    "        self.tf_array = []\n",
    "        self.idf_array = []\n",
    "        self.tfidf_array = []\n",
    "\n",
    "        return self.run_all()\n",
    "\n",
    "    def get_train_data(self,data_frame):\n",
    "        # if train_or_test == 'train':\n",
    "        \n",
    "        self.word_count = []\n",
    "        self.word_count_label = []\n",
    "        self.tf_array = []\n",
    "        self.idf_array = []\n",
    "        self.tfidf_array = []\n",
    "        self.data_frame = data_frame\n",
    "        \n",
    "        return self.run_all()\n",
    "        \n",
    "    def run_all(self,):\n",
    "        self.data_frame.reset_index(inplace= True)\n",
    "        for i in range(len(self.data_frame)):\n",
    "            self.data_frame.text[i] = self.preprocess(str(self.data_frame.text[i]))\n",
    "        \n",
    "        for label in self.data_frame.label.unique():\n",
    "            data_to_process = self.data_frame[self.data_frame.label == label]\n",
    "            data_to_process.drop(columns = ['label'])\n",
    "            wordDict_label = dict.fromkeys(self.wordSet, 0) \n",
    "            for doc_3 in data_to_process.text:\n",
    "                doc_3 = doc_3.split(\" \")\n",
    "                for word in doc_3:\n",
    "                    try:\n",
    "                        if isinstance(wordDict_label[word],int) and (word in self.wordSet):\n",
    "                            wordDict_label[word]+=1\n",
    "                    except :\n",
    "                        pass\n",
    "\n",
    "                wordDict_label['label'] = label\n",
    "                wordDict_label['records'] = len(data_to_process)\n",
    "            self.word_count_label.append(wordDict_label)\n",
    "            # print(label , wordDict_label)\n",
    "            \n",
    "        for doc,label in zip(self.data_frame.text,self.data_frame.label):\n",
    "            doc = doc.split(\" \")\n",
    "            wordDict = dict.fromkeys(self.wordSet, 0)\n",
    "        \n",
    "            for word in doc :\n",
    "                try :\n",
    "                    if word in self.wordSet:\n",
    "                        wordDict[word]+=1\n",
    "                except:\n",
    "                    pass\n",
    "            wordDict['label'] = label\n",
    "            self.word_count.append(wordDict)\n",
    "\n",
    "            tfDict = {}\n",
    "            bowCount = len(doc)\n",
    "            for word, count in wordDict.items():\n",
    "                if  word != 'label' and (word in self.wordSet):\n",
    "                    try :\n",
    "                        tfDict[word] = math.log10(count/float(bowCount)+1.0)\n",
    "                    except:\n",
    "                        pass\n",
    "                tfDict['label'] = label\n",
    "            self.tf_array.append(tfDict)\n",
    "            # print(wordDict)\n",
    "\n",
    "        \n",
    "        idfDict = {}\n",
    "        N = len(self.data_frame)\n",
    "        \n",
    "        idfDict = dict.fromkeys(self.wordSet, 0)\n",
    "        for doc in self.word_count:\n",
    "            for word, val in doc.items():\n",
    "                if word != 'label':\n",
    "                    if val > 0 and (word in self.wordSet):\n",
    "                        try:\n",
    "                            idfDict[word] += 1\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "        for word, val in idfDict.items():\n",
    "            if word  != 'label' and (word in self.wordSet):\n",
    "                try : \n",
    "                    idfDict[word] = math.log10(N / float(val)) if val > 0 else 0\n",
    "                except :\n",
    "                    pass\n",
    "        self.idf_array.append(idfDict)\n",
    "        \n",
    "        tf_df = pd.DataFrame(self.tf_array)\n",
    "        cf_data = pd.DataFrame(self.word_count_label)\n",
    "\n",
    "        for label_index in tf_df.label.unique():\n",
    "            data_to_process = tf_df[tf_df['label'] == label_index]\n",
    "            cf_data_to_process = cf_data[cf_data['label'] == label_index]\n",
    "            cf_data_to_process = cf_data_to_process.drop(columns = ['label'])\n",
    "            n_len = len(cf_data_to_process)\n",
    "            if n_len == 1 :\n",
    "                no_records_per_label = list(cf_data_to_process.records)[0]\n",
    "                cf_data_to_process  = dict(cf_data_to_process.iloc[0,:])\n",
    "            # print(no_records_per_label)\n",
    "            for index,row in data_to_process.iterrows():\n",
    "                # print(row)\n",
    "                tf_dict = dict(row)\n",
    "                tfidf = {}\n",
    "                for word, val in tf_dict.items():\n",
    "                    if word  != 'label' and (word in self.wordSet):\n",
    "                        tfidf[word] = val*idfDict[word]*(cf_data_to_process[word]/no_records_per_label)\n",
    "                        # print((cf_data_to_process[word]))\n",
    "                self.tfidf_array.append(tfidf)\n",
    "            # return tfidf\n",
    "\n",
    "        return (self.word_count,self.tf_array,self.idf_array,self.tfidf_array,self.word_count_label)\n",
    "\n",
    "    # return [row_list,wordDict]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TF-IDF-CF from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((99, 2909), (99, 2909))"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "tfidfcf = get_tftdfcf(trainDF[0:99])\n",
    "result = tfidfcf.get_train_data(train_x[0:99])\n",
    "tfidfcf_data = pd.DataFrame(result[3])\n",
    "\n",
    "result_valid = tfidfcf.get_valid_data(valid_x[0:99])\n",
    "tfidfcf_data_valid = pd.DataFrame(result_valid[3])\n",
    "\n",
    "tfidfcf_data.shape,tfidfcf_data_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                 text       label\n0    great cooooooooooooool album dont blive rando...  __label__2\n1    autobiographi everi caribbean mother jamaica ...  __label__2\n2    realli usabl one hundr twenti knot bend etc p...  __label__2\n3    spine chill awesom grand say enough nightwish...  __label__2\n4    buy someth el dvd documentori alot talk littl...  __label__1\n..                                                ...         ...\n94   album star song listen hardli enjoy listen al...  __label__1\n95   didnt work start indoor cat contract flea mon...  __label__1\n96   excel book guid women divorc process thought ...  __label__2\n97   watch receiv new rhomba excit open tri open g...  __label__1\n98   underwear fond memori wonder dvd set realli a...  __label__2\n\n[99 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>great cooooooooooooool album dont blive rando...</td>\n      <td>__label__2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>autobiographi everi caribbean mother jamaica ...</td>\n      <td>__label__2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>realli usabl one hundr twenti knot bend etc p...</td>\n      <td>__label__2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>spine chill awesom grand say enough nightwish...</td>\n      <td>__label__2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>buy someth el dvd documentori alot talk littl...</td>\n      <td>__label__1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>album star song listen hardli enjoy listen al...</td>\n      <td>__label__1</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>didnt work start indoor cat contract flea mon...</td>\n      <td>__label__1</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>excel book guid women divorc process thought ...</td>\n      <td>__label__2</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>watch receiv new rhomba excit open tri open g...</td>\n      <td>__label__1</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>underwear fond memori wonder dvd set realli a...</td>\n      <td>__label__2</td>\n    </tr>\n  </tbody>\n</table>\n<p>99 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "train_x[0:99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    ages.  track  book.I'm  complicated  Wicked    I  school,  last  kept  \\\n0     0.0    0.0       0.0          0.0     0.0  0.0      0.0   0.0   0.0   \n1     0.0    0.0       0.0          0.0     0.0  0.0      0.0   0.0   0.0   \n2     0.0    0.0       0.0          0.0     0.0  0.0      0.0   0.0   0.0   \n3     0.0    0.0       0.0          0.0     0.0  0.0      0.0   0.0   0.0   \n4     0.0    0.0       0.0          0.0     0.0  0.0      0.0   0.0   0.0   \n..    ...    ...       ...          ...     ...  ...      ...   ...   ...   \n94    0.0    0.0       0.0          0.0     0.0  0.0      0.0   0.0   0.0   \n95    0.0    0.0       0.0          0.0     0.0  0.0      0.0   0.0   0.0   \n96    0.0    0.0       0.0          0.0     0.0  0.0      0.0   0.0   0.0   \n97    0.0    0.0       0.0          0.0     0.0  0.0      0.0   0.0   0.0   \n98    0.0    0.0       0.0          0.0     0.0  0.0      0.0   0.0   0.0   \n\n    them  ...  Utterly,  stay  All  DVD,CD       one      like  became  \\\n0    0.0  ...       0.0   0.0  0.0     0.0  0.000000  0.000000     0.0   \n1    0.0  ...       0.0   0.0  0.0     0.0  0.000000  0.001246     0.0   \n2    0.0  ...       0.0   0.0  0.0     0.0  0.003298  0.000000     0.0   \n3    0.0  ...       0.0   0.0  0.0     0.0  0.003930  0.000000     0.0   \n4    0.0  ...       0.0   0.0  0.0     0.0  0.003020  0.000000     0.0   \n..   ...  ...       ...   ...  ...     ...       ...       ...     ...   \n94   0.0  ...       0.0   0.0  0.0     0.0  0.001673  0.000000     0.0   \n95   0.0  ...       0.0   0.0  0.0     0.0  0.005021  0.000000     0.0   \n96   0.0  ...       0.0   0.0  0.0     0.0  0.000000  0.000000     0.0   \n97   0.0  ...       0.0   0.0  0.0     0.0  0.002175  0.000000     0.0   \n98   0.0  ...       0.0   0.0  0.0     0.0  0.000000  0.000000     0.0   \n\n    unless  thing,  countries  \n0      0.0     0.0        0.0  \n1      0.0     0.0        0.0  \n2      0.0     0.0        0.0  \n3      0.0     0.0        0.0  \n4      0.0     0.0        0.0  \n..     ...     ...        ...  \n94     0.0     0.0        0.0  \n95     0.0     0.0        0.0  \n96     0.0     0.0        0.0  \n97     0.0     0.0        0.0  \n98     0.0     0.0        0.0  \n\n[99 rows x 2909 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ages.</th>\n      <th>track</th>\n      <th>book.I'm</th>\n      <th>complicated</th>\n      <th>Wicked</th>\n      <th>I</th>\n      <th>school,</th>\n      <th>last</th>\n      <th>kept</th>\n      <th>them</th>\n      <th>...</th>\n      <th>Utterly,</th>\n      <th>stay</th>\n      <th>All</th>\n      <th>DVD,CD</th>\n      <th>one</th>\n      <th>like</th>\n      <th>became</th>\n      <th>unless</th>\n      <th>thing,</th>\n      <th>countries</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.001246</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.003298</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.003930</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.003020</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.001673</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.005021</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.002175</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>99 rows × 2909 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "tfidfcf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other vectorizations for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "# import pandas, xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "# from keras import layers, models, optimizers\n",
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(trainDF['text'][0:99])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x.text[0:99])\n",
    "xvalid_count =  count_vect.transform(valid_x.text[0:99])\n",
    "\n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "tfidf_vect.fit(trainDF['text'][0:99])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x.text[0:99])\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x.text[0:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, y_valid_data, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, y_valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "NB, WordLevel TF-IDF-CF:  0.5353535353535354\nNB, Count Vectors:  0.5959595959595959\nNB, WordLevel TF-IDF:  0.5858585858585859\n"
    }
   ],
   "source": [
    "# Naive Bayes on tfidfcf\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), np.array(tfidfcf_data), train_y[0:99], np.array(tfidfcf_data_valid),valid_y[0:99])\n",
    "print(\"NB, WordLevel TF-IDF-CF: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Count Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y[0:99], xvalid_count,valid_y[0:99])\n",
    "print(\"NB, Count Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y[0:99], xvalid_tfidf,valid_y[0:99])\n",
    "print(\"NB, WordLevel TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks :\n",
    "\n",
    "custom TF-IDF-CF seems to be working poorly when compared to existing vectorizations but not actually bad .   \n",
    "it might increase in performace with increase in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitvenvvenvdf858f60afa84ff0802227ffd6401940",
   "display_name": "Python 3.7.7 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}